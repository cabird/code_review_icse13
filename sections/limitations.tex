%!TEX root = ../paper.tex

%%%%%%%%%%%%%%%%%%%%%%
\section{Limitations} \label{sec:limitations}
%%%%%%%%%%%%%%%%%%%%%%


As a qualitative study, gauging the validity of our findings is a difficult undertaking~\cite{golafshani2003understanding}. While we have endeavored to uncover and report the expectations, outcomes, and challenges of code review, limitations may exist. We describe them with the steps that we took to increase confidence and validity.

To achieve a comprehensive view of code review, we triangulated by collecting and comparing results from multiple sources. For example, we found strong agreement among the results of expectations collected from interviews, surveys of manager, and surveys of developers. By starting with exploratory interviews of a smaller set of subjects (17) followed by open coding to extract themes, we identified core questions that we addressed to a larger audience via survey.

One potential criticism is that empirical research within one company or one project provides little value for the academic community, and does not contribute to scientific development. Historical evidence shows otherwise. Flyvbjerg provides several examples of individual cases that contributed to discovery in physics, economics, and social science~\cite{flyvbjerg2006five}. Beveridge observed for social sciences: \quotation{More discoveries have arisen from intense observation than from statistics applied to large groups} (as quoted in Kuper and Kuper~\cite{kuper1995social}, page 95). This should not be interpreted as a criticism of research that focuses on large samples. For the development of an empirical body of knowledge as championed by Basili~\cite{basili1999building}, both types of research are essential. To understand code review across many contexts, we observed, interviewed, surveyed, and examined code reviews from developers across a diverse group of software teams that work with codebases in various domains, of varying sizes, and with varying processes.

Concerning the representativeness of our results in other contexts, other companies and OSS use tools similar to CodeFlow~\cite{gerrit2012online, tsotsis2011online, kennedy2006online}. However, team dynamics may differ. The need for code understanding may already be met in contexts where projects are smaller or there is shared code ownership and a broad system understanding across the team. We found that higher levels of understanding lead to more informative comments, which identify defects or aid the author in other ways so review in these contexts may uncover more defects. In OSS contexts, project-specific expertise often must be demonstrated prior to being accepted as a ``core committer''~\cite{bird2007open}, so learning may not be as important or frequent an outcome for review.

In this work, we have used discussions within CodeFlow to identify and quantify outcomes of code review. However, some motivations that managers and developers described are not easily observable because they leave little trace. For example, determining how often code review improves team awareness or transfers knowledge is difficult to assess from the discussions in reviews. For these outcomes, we have responses indicating that they occur, but not ``hard evidence.''

Based on review comments, survey responses, and interviews, we know that in-person discussions occurred frequently. While we cannot compare frequency of these events to other outcomes as we can with events recorded in CodeFlow, we know that they most often occurred to address understanding needs.

